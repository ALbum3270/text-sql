#!/usr/bin/env python3
"""
åŸºäºŽ Gold Samples ä¼˜åŒ– KB æè¿°

æ ¹æ®å¸¸è§é—®é¢˜æ¨¡å¼è‡ªåŠ¨ä¼˜åŒ–çŸ¥è¯†åº“æè¿°
"""

import json
from collections import defaultdict, Counter
import re

def analyze_question_patterns(samples):
    """åˆ†æžé—®é¢˜æ¨¡å¼ï¼Œæå–å…³é”®è¯"""
    table_patterns = defaultdict(lambda: defaultdict(list))
    
    for sample in samples:
        question = sample["question"]
        tables = sample["must_tables"]
        
        for table in tables:
            # åˆ†æžé—®é¢˜ä¸­çš„å…³é”®è¯æ¨¡å¼
            if "æ€»æ•°" in question or "æ•°é‡" in question:
                table_patterns[table]["count_keywords"].append("æ€»æ•°ç»Ÿè®¡")
                table_patterns[table]["count_keywords"].append("æ•°é‡æŸ¥è¯¢")
            
            if "æŒ‰" in question and "ç»Ÿè®¡" in question:
                table_patterns[table]["group_keywords"].append("åˆ†ç»„ç»Ÿè®¡")
                table_patterns[table]["group_keywords"].append("æŒ‰ç±»åˆ«ç»Ÿè®¡")
            
            if "ç§Ÿæˆ·" in question:
                table_patterns[table]["tenant_keywords"].append("ç§Ÿæˆ·è¿‡æ»¤")
                table_patterns[table]["tenant_keywords"].append("å¤šç§Ÿæˆ·")
            
            if "ä»Šå¤©" in question:
                table_patterns[table]["time_keywords"].append("ä»Šå¤©")
                table_patterns[table]["time_keywords"].append("å½“æ—¥ç»Ÿè®¡")
            
            if "è¿‘" in question:
                table_patterns[table]["time_keywords"].append("æ—¶é—´èŒƒå›´")
                table_patterns[table]["time_keywords"].append("åŽ†å²ç»Ÿè®¡")
            
            if "è¶‹åŠ¿" in question:
                table_patterns[table]["trend_keywords"].append("è¶‹åŠ¿åˆ†æž")
                table_patterns[table]["trend_keywords"].append("æ—¶é—´åºåˆ—")
            
            if "å¨èƒ" in question:
                table_patterns[table]["threat_keywords"].append("å¨èƒæ£€æµ‹")
                table_patterns[table]["threat_keywords"].append("å®‰å…¨å¨èƒ")
            
            if "åŸŸå" in question:
                table_patterns[table]["domain_keywords"].append("åŸŸåç®¡ç†")
                table_patterns[table]["domain_keywords"].append("DNSå®‰å…¨")
            
            if "ç»ˆç«¯" in question or "èŠ‚ç‚¹" in question:
                table_patterns[table]["endpoint_keywords"].append("ç»ˆç«¯ç®¡ç†")
                table_patterns[table]["endpoint_keywords"].append("è®¾å¤‡ç›‘æŽ§")
            
            if "ç—…æ¯’" in question:
                table_patterns[table]["virus_keywords"].append("ç—…æ¯’æ£€æµ‹")
                table_patterns[table]["virus_keywords"].append("æ¶æ„è½¯ä»¶")
            
            if "å¼±å£ä»¤" in question:
                table_patterns[table]["password_keywords"].append("å¼±å£ä»¤æ£€æŸ¥")
                table_patterns[table]["password_keywords"].append("å¯†ç å®‰å…¨")
            
            if "æ¼æ´ž" in question:
                table_patterns[table]["vuln_keywords"].append("æ¼æ´žæ‰«æ")
                table_patterns[table]["vuln_keywords"].append("å®‰å…¨æ¼æ´ž")
    
    return table_patterns

def generate_kb_optimizations(table_patterns):
    """ç”ŸæˆKBä¼˜åŒ–å»ºè®®"""
    optimizations = {}
    
    for table, patterns in table_patterns.items():
        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        all_keywords = []
        for category, keywords in patterns.items():
            all_keywords.extend(set(keywords))
        
        # æ ¹æ®tableåç§°ç¡®å®šä¸»è¦ç”¨é€”
        base_purpose = ""
        enhanced_keywords = []
        
        if "virus" in table.lower():
            base_purpose = "ç—…æ¯’æ„ŸæŸ“è®°å½•ï¼Œæ¶æ„è½¯ä»¶æ£€æµ‹ï¼Œç»ˆç«¯å®‰å…¨å¨èƒ"
            enhanced_keywords.extend(["ç—…æ¯’æ„ŸæŸ“", "æ¶æ„è½¯ä»¶", "å®‰å…¨å¨èƒ", "ç»ˆç«¯é˜²æŠ¤"])
        
        elif "threat" in table.lower():
            if "domain" in table.lower():
                base_purpose = "å¨èƒåŸŸåï¼Œæ¶æ„åŸŸåï¼ŒåŸŸåé»‘åå•ï¼ŒDNSå®‰å…¨å¨èƒ"
                enhanced_keywords.extend(["å¨èƒåŸŸå", "æ¶æ„åŸŸå", "DNSå¨èƒ", "åŸŸåå®‰å…¨"])
            elif "ip" in table.lower():
                base_purpose = "å¨èƒIPï¼Œæ¶æ„IPåœ°å€ï¼Œç½‘ç»œå®‰å…¨å¨èƒ"
                enhanced_keywords.extend(["å¨èƒIP", "æ¶æ„IP", "ç½‘ç»œå¨èƒ", "IPå®‰å…¨"])
            elif "process" in table.lower():
                base_purpose = "å¨èƒè¿›ç¨‹ï¼Œæ¶æ„è¿›ç¨‹ï¼Œè¿›ç¨‹å®‰å…¨ç›‘æŽ§"
                enhanced_keywords.extend(["å¨èƒè¿›ç¨‹", "æ¶æ„è¿›ç¨‹", "è¿›ç¨‹ç›‘æŽ§", "è¿›ç¨‹å®‰å…¨"])
            else:
                base_purpose = "å®‰å…¨å¨èƒï¼Œå¨èƒæƒ…æŠ¥ï¼Œå®‰å…¨ç›‘æŽ§"
                enhanced_keywords.extend(["å®‰å…¨å¨èƒ", "å¨èƒæ£€æµ‹", "å®‰å…¨ç›‘æŽ§"])
        
        elif "weak_password" in table.lower():
            base_purpose = "å¼±å£ä»¤æ£€æŸ¥ï¼Œå¯†ç å®‰å…¨ï¼Œç»ˆç«¯å¼±å¯†ç æ£€æµ‹"
            enhanced_keywords.extend(["å¼±å£ä»¤", "å¯†ç å®‰å…¨", "å¼±å¯†ç ", "å£ä»¤æ£€æŸ¥"])
        
        elif "node" in table.lower():
            if "statistics" in table.lower():
                base_purpose = "ç»ˆç«¯çŠ¶æ€ç»Ÿè®¡ï¼ŒèŠ‚ç‚¹è¿žæŽ¥çŠ¶æ€ï¼Œåœ¨çº¿ç¦»çº¿ç»Ÿè®¡ï¼Œç»ˆç«¯ç›‘æŽ§"
                enhanced_keywords.extend(["ç»ˆç«¯çŠ¶æ€", "åœ¨çº¿ç»Ÿè®¡", "èŠ‚ç‚¹ç›‘æŽ§", "è¿žæŽ¥çŠ¶æ€"])
            else:
                base_purpose = "ç»ˆç«¯è®¾å¤‡ï¼ŒèŠ‚ç‚¹ä¿¡æ¯ï¼Œè®¾å¤‡ç®¡ç†ï¼Œç»ˆç«¯åŸºç¡€ä¿¡æ¯"
                enhanced_keywords.extend(["ç»ˆç«¯è®¾å¤‡", "èŠ‚ç‚¹ä¿¡æ¯", "è®¾å¤‡ç®¡ç†", "ç»ˆç«¯åŸºç¡€"])
        
        elif "vulnerability" in table.lower():
            base_purpose = "æ¼æ´žæ‰«æï¼Œå®‰å…¨æ¼æ´žï¼Œæ¼æ´žæ£€æµ‹ï¼Œå®‰å…¨è¯„ä¼°"
            enhanced_keywords.extend(["æ¼æ´žæ‰«æ", "å®‰å…¨æ¼æ´ž", "æ¼æ´žæ£€æµ‹", "å®‰å…¨è¯„ä¼°"])
        
        elif "container" in table.lower():
            base_purpose = "å®¹å™¨ç®¡ç†ï¼ŒDockerå®¹å™¨ï¼Œå®¹å™¨ç»Ÿè®¡ï¼Œå®¹å™¨ç›‘æŽ§"
            enhanced_keywords.extend(["å®¹å™¨ç®¡ç†", "Docker", "å®¹å™¨ç»Ÿè®¡", "å®¹å™¨ç›‘æŽ§"])
        
        elif "base_line" in table.lower():
            base_purpose = "åŸºçº¿æ£€æŸ¥ï¼Œå®‰å…¨åŸºçº¿ï¼Œé…ç½®æ£€æŸ¥ï¼Œåˆè§„æ£€æŸ¥"
            enhanced_keywords.extend(["åŸºçº¿æ£€æŸ¥", "å®‰å…¨åŸºçº¿", "åˆè§„æ£€æŸ¥", "é…ç½®å®¡è®¡"])
        
        elif "attck" in table.lower():
            base_purpose = "æ”»å‡»å‘Šè­¦ï¼Œå®‰å…¨å‘Šè­¦ï¼Œæ”»å‡»æ£€æµ‹ï¼Œå®‰å…¨äº‹ä»¶"
            enhanced_keywords.extend(["æ”»å‡»å‘Šè­¦", "å®‰å…¨å‘Šè­¦", "æ”»å‡»æ£€æµ‹", "å®‰å…¨äº‹ä»¶"])
        
        else:
            base_purpose = f"{table} ç›¸å…³æ•°æ®ç®¡ç†"
            enhanced_keywords.extend([table.replace("_", " ")])
        
        # æ·»åŠ ä»Žé—®é¢˜æ¨¡å¼ä¸­æå–çš„å…³é”®è¯
        enhanced_keywords.extend(all_keywords)
        enhanced_keywords = list(set(enhanced_keywords))  # åŽ»é‡
        
        optimizations[table] = {
            "current_purpose": f"{table} ç›¸å…³æ•°æ®ç®¡ç†",  # å‡è®¾çš„å½“å‰æè¿°
            "enhanced_purpose": base_purpose + "ï¼Œ" + "ï¼Œ".join(enhanced_keywords[:8]),  # é™åˆ¶é•¿åº¦
            "aliases": enhanced_keywords[:15],  # å‰15ä¸ªä½œä¸ºåˆ«å
            "question_count": len(table_patterns[table])
        }
    
    return optimizations

def apply_kb_optimizations(optimizations, kb_file="outputs/kb/kb_catalog.json"):
    """åº”ç”¨KBä¼˜åŒ–åˆ°å®žé™…æ–‡ä»¶"""
    print(f"ðŸ“ æ­£åœ¨ä¼˜åŒ– {kb_file}...")
    
    # è¯»å–å½“å‰KB
    with open(kb_file, 'r', encoding='utf-8') as f:
        kb_data = json.load(f)
    
    updated_tables = []
    
    # æŸ¥æ‰¾å¹¶æ›´æ–°è¡¨æè¿°
    for table_info in kb_data.get("tables", []):
        table_name = table_info.get("name")
        if table_name in optimizations:
            opt = optimizations[table_name]
            
            # æ›´æ–°purpose
            old_purpose = table_info.get("purpose", "")
            table_info["purpose"] = opt["enhanced_purpose"]
            
            # æ›´æ–°grainï¼ˆå¯é€‰ï¼‰
            table_info["grain"] = f"æ¯è¡Œ={table_name}è®°å½•ï¼Œæ”¯æŒ{opt['aliases'][0] if opt['aliases'] else 'æ•°æ®æŸ¥è¯¢'}"
            
            updated_tables.append({
                "name": table_name,
                "old": old_purpose,
                "new": opt["enhanced_purpose"]
            })
            
            print(f"âœ… å·²æ›´æ–° {table_name}")
    
    # å†™å›žæ–‡ä»¶
    with open(kb_file, 'w', encoding='utf-8') as f:
        json.dump(kb_data, f, ensure_ascii=False, indent=2)
    
    return updated_tables

def generate_few_shot_examples(samples, output_file="few_shot_examples.json"):
    """ç”Ÿæˆfew-shotç¤ºä¾‹"""
    # æŒ‰ç±»åž‹é€‰æ‹©æœ€ä½³ç¤ºä¾‹
    categories = {
        "count": [],
        "group": [],
        "time_range": [],
        "threat": [],
        "endpoint": []
    }
    
    for sample in samples:
        question = sample["question"]
        
        if "æ€»æ•°" in question:
            categories["count"].append(sample)
        elif "æŒ‰" in question and "ç»Ÿè®¡" in question:
            categories["group"].append(sample)
        elif "è¿‘" in question or "ä»Šå¤©" in question:
            categories["time_range"].append(sample)
        elif "å¨èƒ" in question:
            categories["threat"].append(sample)
        elif "ç»ˆç«¯" in question or "èŠ‚ç‚¹" in question:
            categories["endpoint"].append(sample)
    
    # æ¯ç±»é€‰æ‹©1-2ä¸ªæœ€ä½³ç¤ºä¾‹
    few_shot_examples = []
    for category, examples in categories.items():
        if examples:
            # é€‰æ‹©SQLç›¸å¯¹ç®€å•çš„ç¤ºä¾‹
            examples.sort(key=lambda x: len(x["gold_sql"]))
            few_shot_examples.extend(examples[:2])
    
    # ä¿å­˜few-shotç¤ºä¾‹
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(few_shot_examples[:6], f, ensure_ascii=False, indent=2)
    
    print(f"ðŸ’¡ å·²ç”Ÿæˆ {len(few_shot_examples[:6])} ä¸ªfew-shotç¤ºä¾‹åˆ° {output_file}")
    return few_shot_examples[:6]

def main():
    print("ðŸš€ åŸºäºŽ Gold Samples çš„ KB ä¼˜åŒ–å·¥å…·")
    print("=" * 50)
    
    # åŠ è½½gold samples
    with open("gold_samples.jsonl", 'r', encoding='utf-8') as f:
        samples = [json.loads(line) for line in f if line.strip()]
    
    print(f"ðŸ“¥ åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    
    # åˆ†æžé—®é¢˜æ¨¡å¼
    print("ðŸ” åˆ†æžé—®é¢˜æ¨¡å¼...")
    table_patterns = analyze_question_patterns(samples)
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    print("ðŸ’¡ ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
    optimizations = generate_kb_optimizations(table_patterns)
    
    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
    print("\nðŸ“‹ KB ä¼˜åŒ–å»ºè®®:")
    for table, opt in sorted(optimizations.items(), key=lambda x: x[1]["question_count"], reverse=True)[:10]:
        print(f"\nðŸŽ¯ {table} (å‡ºçŽ°{opt['question_count']}æ¬¡):")
        print(f"   å½“å‰: {opt['current_purpose']}")
        print(f"   ä¼˜åŒ–: {opt['enhanced_purpose']}")
        print(f"   åˆ«å: {', '.join(opt['aliases'][:5])}...")
    
    # è¯¢é—®æ˜¯å¦åº”ç”¨ä¼˜åŒ–
    if input("\nðŸ”§ æ˜¯å¦åº”ç”¨è¿™äº›ä¼˜åŒ–åˆ° kb_catalog.json? (y/N): ").lower() == 'y':
        updated = apply_kb_optimizations(optimizations)
        print(f"âœ… å·²æ›´æ–° {len(updated)} ä¸ªè¡¨çš„æè¿°")
    
    # ç”Ÿæˆfew-shotç¤ºä¾‹
    print("\nðŸ’¡ ç”Ÿæˆfew-shotç¤ºä¾‹...")
    few_shot = generate_few_shot_examples(samples)
    
    print("\nðŸ“Š æŽ¨èfew-shotç¤ºä¾‹:")
    for i, example in enumerate(few_shot, 1):
        print(f"  {i}. {example['question']}")
        print(f"     -> ä½¿ç”¨è¡¨: {', '.join(example['must_tables'])}")

if __name__ == "__main__":
    main()
